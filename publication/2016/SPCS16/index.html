<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.fabc54768ab4e8748965ae69f556c884.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=description content="The correct understanding of the 3D shape is a crucial aspect to improve the 3D scanning process, especially in order to perform high quality and as complete as possible 3D acquisitions on the field. The paper proposes a new technique to enhance the visualization of raw scanning data based on the definition in device space of a Multi-View Ambient Occlusion (MVAO). The approach allows improving the comprehension of the 3D shape of the input geometry and, requiring almost no preprocessing, it can be directly applied to raw captured point clouds. The algorithm has been tested on different datasets: high resolution Time-of-Flight scans and streams of low quality range maps from a depth camera. The results enhance the details perception in the 3D geometry using the multi-view information to make more robust the ambient occlusion estimation."><link rel=alternate hreflang=en-us href=http://vcg.isti.cnr.it/publication/2016/SPCS16/><link rel=canonical href=http://vcg.isti.cnr.it/publication/2016/SPCS16/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu99235f83657eda8c6e6761af9b1430df_128410_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu99235f83657eda8c6e6761af9b1430df_128410_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="http://vcg.isti.cnr.it/publication/2016/SPCS16/featured.jpg"><meta property="og:site_name" content="Visual Computing Lab"><meta property="og:url" content="http://vcg.isti.cnr.it/publication/2016/SPCS16/"><meta property="og:title" content="Multi-View Ambient Occlusion for Enhancing Visualization of Raw Scanning Data | Visual Computing Lab"><meta property="og:description" content="The correct understanding of the 3D shape is a crucial aspect to improve the 3D scanning process, especially in order to perform high quality and as complete as possible 3D acquisitions on the field. The paper proposes a new technique to enhance the visualization of raw scanning data based on the definition in device space of a Multi-View Ambient Occlusion (MVAO). The approach allows improving the comprehension of the 3D shape of the input geometry and, requiring almost no preprocessing, it can be directly applied to raw captured point clouds. The algorithm has been tested on different datasets: high resolution Time-of-Flight scans and streams of low quality range maps from a depth camera. The results enhance the details perception in the 3D geometry using the multi-view information to make more robust the ambient occlusion estimation."><meta property="og:image" content="http://vcg.isti.cnr.it/publication/2016/SPCS16/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2016-01-01T00:00:00+00:00"><meta property="article:modified_time" content="2016-01-01T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"http://vcg.isti.cnr.it/publication/2016/SPCS16/"},"headline":"Multi-View Ambient Occlusion for Enhancing Visualization of Raw Scanning Data","image":["http://vcg.isti.cnr.it/publication/2016/SPCS16/featured.jpg"],"datePublished":"2016-01-01T00:00:00Z","dateModified":"2016-01-01T00:00:00Z","author":{"@type":"Person","name":"Manuele Sabbadin"},"publisher":{"@type":"Organization","name":"Visual Computing Lab","logo":{"@type":"ImageObject","url":"http://vcg.isti.cnr.it/media/icon_hu99235f83657eda8c6e6761af9b1430df_128410_192x192_fill_lanczos_center_3.png"}},"description":"The correct understanding of the 3D shape is a crucial aspect to improve the 3D scanning process, especially in order to perform high quality and as complete as possible 3D acquisitions on the field. The paper proposes a new technique to enhance the visualization of raw scanning data based on the definition in device space of a Multi-View Ambient Occlusion (MVAO). The approach allows improving the comprehension of the 3D shape of the input geometry and, requiring almost no preprocessing, it can be directly applied to raw captured point clouds. The algorithm has been tested on different datasets: high resolution Time-of-Flight scans and streams of low quality range maps from a depth camera. The results enhance the details perception in the 3D geometry using the multi-view information to make more robust the ambient occlusion estimation."}</script><title>Multi-View Ambient Occlusion for Enhancing Visualization of Raw Scanning Data | Visual Computing Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=33343423c9c6c8bb663b666fb6505fb9><script src=/js/wowchemy-init.min.2bb937f129e5d9a1df7980a60ff6010c.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Visual Computing Lab</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Visual Computing Lab</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/research><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/results><span>Activities</span></a></li><li class=nav-item><a class=nav-link href=/software><span>Software</span></a></li><li class=nav-item><a class=nav-link href=/courses><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="article-container pt-3"><h1>Multi-View Ambient Occlusion for Enhancing Visualization of Raw Scanning Data</h1><div class=article-metadata><div><span><a href=/author/Manuele-Sabbadin/>Manuele Sabbadin</a></span>, <span><a href=/author/Gianpaolo-Palma/>Gianpaolo Palma</a></span>, <span><a href=/author/Paolo-Cignoni/>Paolo Cignoni</a></span>, <span><a href=/author/Roberto-Scopigno/>Roberto Scopigno</a></span></div><span class=pub-publication><em>14th Eurographics Workshops on Graphics and Cultural Heritage (EG GCH 2016)</em>
</span>-
<span class=article-date>January 2016</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://vcgdata.isti.cnr.it/Publications/2016/SPCS16/final.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/2016/SPCS16/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header" href=https://vcgdata.isti.cnr.it/Publications/2016/SPCS16/MVAO_maschiAngioino.mp4 target=_blank rel=noopener>Video
</a><a class="btn btn-outline-primary btn-page-header" href=https://doi.org/10.2312/gch.20161379 target=_blank rel=noopener>DOI</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:421px><div style=position:relative><img src=/publication/2016/SPCS16/featured_hu13486e1c99b93e61f27cc4df4e99c339_198833_720x2500_fit_q75_h2_lanczos.webp width=720 height=421 alt class=featured-image></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>The correct understanding of the 3D shape is a crucial aspect to improve the 3D scanning process, especially in order to perform high quality and as complete as possible 3D acquisitions on the field. The paper proposes a new technique to enhance the visualization of raw scanning data based on the definition in device space of a Multi-View Ambient Occlusion (MVAO). The approach allows improving the comprehension of the 3D shape of the input geometry and, requiring almost no preprocessing, it can be directly applied to raw captured point clouds. The algorithm has been tested on different datasets: high resolution Time-of-Flight scans and streams of low quality range maps from a depth camera. The results enhance the details perception in the 3D geometry using the multi-view information to make more robust the ambient occlusion estimation.</p><div class=article-style></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2016%2FSPCS16%2F&amp;text=Multi-View+Ambient+Occlusion+for+Enhancing+Visualization+of+Raw+Scanning+Data" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2016%2FSPCS16%2F&amp;t=Multi-View+Ambient+Occlusion+for+Enhancing+Visualization+of+Raw+Scanning+Data" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Multi-View%20Ambient%20Occlusion%20for%20Enhancing%20Visualization%20of%20Raw%20Scanning%20Data&amp;body=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2016%2FSPCS16%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2016%2FSPCS16%2F&amp;title=Multi-View+Ambient+Occlusion+for+Enhancing+Visualization+of+Raw+Scanning+Data" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Multi-View+Ambient+Occlusion+for+Enhancing+Visualization+of+Raw+Scanning+Data%20http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2016%2FSPCS16%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2016%2FSPCS16%2F&amp;title=Multi-View+Ambient+Occlusion+for+Enhancing+Visualization+of+Raw+Scanning+Data" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=/author/Gianpaolo-Palma/><img class="avatar mr-3 avatar-circle" src=/author/Gianpaolo-Palma/avatar_huea6aa494dc8148c5ef0b291eeda4f548_22641_270x270_fill_q75_lanczos_center.jpg alt="Gianpaolo Palma"></a><div class=media-body><h5 class=card-title><a href=/author/Gianpaolo-Palma/>Gianpaolo Palma</a></h5><h6 class=card-subtitle>Researcher</h6><ul class=network-icon aria-hidden=true><li><a href=mailto:gianpaolo.palma@isti.cnr.it><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=H5bysMsAAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://orcid.org/0000-0002-1032-2092 target=_blank rel=noopener><i class="fab fa-orcid"></i></a></li><li><a href=https://github.com/gianpaolopalma target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/author/Paolo-Cignoni/><img class="avatar mr-3 avatar-circle" src=/author/Paolo-Cignoni/avatar_hu0e2f4595d8119771d74856739d667e82_351152_270x270_fill_q75_lanczos_center.jpg alt="Paolo Cignoni"></a><div class=media-body><h5 class=card-title><a href=/author/Paolo-Cignoni/>Paolo Cignoni</a></h5><h6 class=card-subtitle>Research Director</h6><ul class=network-icon aria-hidden=true><li><a href=mailto:paolo.cignoni@isti.cnr.it><i class="fas fa-envelope"></i></a></li><li><a href=https://orcid.org/0000-0002-2686-8567 target=_blank rel=noopener><i class="fab fa-orcid"></i></a></li><li><a href="https://scholar.google.com/citations?user=nz0WWGsAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://twitter.com/ALoopingIcon target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href=https://github.com/cignoni target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> â€” the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.4922cd6d3d810ab587afa7cdb3851db6.js></script><script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.af9327db0521d4a01354bfc8b77a4324.js type=module></script></body></html>