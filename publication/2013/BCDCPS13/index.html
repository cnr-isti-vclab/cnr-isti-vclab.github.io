<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.7"><link rel=stylesheet href=/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.ca0a49c9e5a9ea264507e4f6c4c97b72.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=description content="abstract






AbstractIn this paper, we present EnvyDepth, an interface for recovering local illumination from a single HDR environment map. In EnvyDepth, the user quickly indicates strokes to mark regions of the environment map that should be grouped together in a single geometric primitive. From these annotated strokes, EnvyDepth uses edit propagation to create a detailed collection of virtual point lights that reproduce both the local and the distant lighting effects in the original scene. When compared to the sole use of the distant illumination, the added spatial information better reproduces a variety of local effects such as shadows, highlights and caustics. Without the effort needed to create precise scene reconstructions, EnvyDepth annotations take only tens of seconds to produce a plausible lighting without visible artifacts. This is easy to obtain even in the case of complex scenes, both indoors and outdoors. The generated lighting environments work well in a production pipeline since they are efficient to use and able to produce accurate renderings.





Errata: the Amsterdam Road example is not in Amsterdam but in Hague.

SoftwareA first version of EnvyDepth can be now dowloaded here; spiced by  Piccante. Tutorial Video"><link rel=alternate hreflang=en-us href=http://vcg.isti.cnr.it/publication/2013/BCDCPS13/><link rel=canonical href=http://vcg.isti.cnr.it/publication/2013/BCDCPS13/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu99235f83657eda8c6e6761af9b1430df_128410_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu99235f83657eda8c6e6761af9b1430df_128410_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@GetResearchDev"><meta property="twitter:creator" content="@GetResearchDev"><meta property="twitter:image" content="http://vcg.isti.cnr.it/publication/2013/BCDCPS13/featured.jpg"><meta property="og:type" content="article"><meta property="og:site_name" content="Visual Computing Lab"><meta property="og:url" content="http://vcg.isti.cnr.it/publication/2013/BCDCPS13/"><meta property="og:title" content="EnvyDepth: An Interface for Recovering Local Natural Illumination from Environment Maps | Visual Computing Lab"><meta property="og:description" content="abstract






AbstractIn this paper, we present EnvyDepth, an interface for recovering local illumination from a single HDR environment map. In EnvyDepth, the user quickly indicates strokes to mark regions of the environment map that should be grouped together in a single geometric primitive. From these annotated strokes, EnvyDepth uses edit propagation to create a detailed collection of virtual point lights that reproduce both the local and the distant lighting effects in the original scene. When compared to the sole use of the distant illumination, the added spatial information better reproduces a variety of local effects such as shadows, highlights and caustics. Without the effort needed to create precise scene reconstructions, EnvyDepth annotations take only tens of seconds to produce a plausible lighting without visible artifacts. This is easy to obtain even in the case of complex scenes, both indoors and outdoors. The generated lighting environments work well in a production pipeline since they are efficient to use and able to produce accurate renderings.





Errata: the Amsterdam Road example is not in Amsterdam but in Hague.

SoftwareA first version of EnvyDepth can be now dowloaded here; spiced by  Piccante. Tutorial Video"><meta property="og:image" content="http://vcg.isti.cnr.it/publication/2013/BCDCPS13/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2013-01-01T00:00:00+00:00"><meta property="article:modified_time" content="2013-01-01T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"http://vcg.isti.cnr.it/publication/2013/BCDCPS13/"},"headline":"EnvyDepth: An Interface for Recovering Local Natural Illumination from Environment Maps","image":["http://vcg.isti.cnr.it/publication/2013/BCDCPS13/featured.jpg"],"datePublished":"2013-01-01T00:00:00Z","dateModified":"2013-01-01T00:00:00Z","author":{"@type":"Person","name":"Francesco Banterle"},"publisher":{"@type":"Organization","name":"Visual Computing Lab","logo":{"@type":"ImageObject","url":null}},"description":"abstract\n\n\n\n\n\n\nAbstractIn this paper, we present EnvyDepth, an interface for recovering local illumination from a single HDR environment map. In EnvyDepth, the user quickly indicates strokes to mark regions of the environment map that should be grouped together in a single geometric primitive. From these annotated strokes, EnvyDepth uses edit propagation to create a detailed collection of virtual point lights that reproduce both the local and the distant lighting effects in the original scene. When compared to the sole use of the distant illumination, the added spatial information better reproduces a variety of local effects such as shadows, highlights and caustics. Without the effort needed to create precise scene reconstructions, EnvyDepth annotations take only tens of seconds to produce a plausible lighting without visible artifacts. This is easy to obtain even in the case of complex scenes, both indoors and outdoors. The generated lighting environments work well in a production pipeline since they are efficient to use and able to produce accurate renderings.\n\n\n\n\n\nErrata: the Amsterdam Road example is not in Amsterdam but in Hague.\n\nSoftwareA first version of EnvyDepth can be now dowloaded here; spiced by  Piccante. Tutorial Video"}</script><title>EnvyDepth: An Interface for Recovering Local Natural Illumination from Environment Maps | Visual Computing Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=d68c07fbca43f8477b8607ed3ffcf658><script src=/js/wowchemy-init.min.af58bb76e2f77811e22a6e43ed4f8bfa.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><img src=/media/logo_hu99235f83657eda8c6e6761af9b1430df_128410_0x140_resize_lanczos_3.png alt="Visual Computing Lab">
</a><a class=navbar-brand href=https:\\www.isti.cnr.it><img src=/media/isti_hu52433adf7761dacaa8b2bdc0e4b3eb6a_12728_0x140_resize_lanczos_3.png alt=ISTI class=logo_light>
<img src=/media/isti_white_hucfe3150eddc44201734eae28df9606f2_8927_0x140_resize_lanczos_3.png alt=ISTI class=logo_dark>
</a><a class=navbar-brand href=https:\\www.cnr.it><img src=/media/cnr_hu2d14b5b0f96bfaa4a005f87f1d1b3b34_10051_0x140_resize_lanczos_3.png alt=CNR class=logo_light>
<img src=/media/cnr_white_hu180cac60f9bff7eeffa9eaabc33519c3_7619_0x140_resize_lanczos_3.png alt=CNR class=logo_dark></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><img src=/media/logo_hu99235f83657eda8c6e6761af9b1430df_128410_0x140_resize_lanczos_3.png alt="Visual Computing Lab">
</a><a class=navbar-brand href=https:\\www.isti.cnr.it><img src=/media/isti_hu52433adf7761dacaa8b2bdc0e4b3eb6a_12728_0x140_resize_lanczos_3.png alt=ISTI class=logo_light>
<img src=/media/isti_white_hucfe3150eddc44201734eae28df9606f2_8927_0x140_resize_lanczos_3.png alt=ISTI class=logo_dark>
</a><a class=navbar-brand href=https:\\www.cnr.it><img src=/media/cnr_hu2d14b5b0f96bfaa4a005f87f1d1b3b34_10051_0x140_resize_lanczos_3.png alt=CNR class=logo_light>
<img src=/media/cnr_white_hu180cac60f9bff7eeffa9eaabc33519c3_7619_0x140_resize_lanczos_3.png alt=CNR class=logo_dark></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/research><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/results><span>Activities</span></a></li><li class=nav-item><a class=nav-link href=/software><span>Software</span></a></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>EnvyDepth: An Interface for Recovering Local Natural Illumination from Environment Maps</h1><div class=article-metadata><div><span class=author-highlighted><a href=/author/Francesco-Banterle/>Francesco Banterle</a></span>, <span><a href=/author/Marco-Callieri/>Marco Callieri</a></span>, <span><a href=/author/Matteo-Dellepiane/>Matteo Dellepiane</a></span>, <span><a href=/author/Massimiliano-Corsini/>Massimiliano Corsini</a></span>, <span><a href=/author/Fabio-Pellacini/>Fabio Pellacini</a></span>, <span><a href=/author/Roberto-Scopigno/>Roberto Scopigno</a></span></div><span class=pub-publication><em>Computer Graphics Forum</em>
</span>-
<span class=article-date>January 2013</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://vcgdata.isti.cnr.it/Publications/2013/BCDCPS13/main.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/2013/BCDCPS13/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header" href=https://vcgdata.isti.cnr.it/Publications/2013/BCDCPS13/video.wmv target=_blank rel=noopener>Video</a></div></div><div class="universal-wrapper featured-image-wrapper mt-4 mb-4" style=max-width:697px;max-height:326px><div style=position:relative><img src=/publication/2013/BCDCPS13/featured_hu029503013c34d5893ec5d858c1a250c7_60216_720x2500_fit_q75_h2_lanczos.webp width=697 height=326 alt class=featured-image></div></div><div class=universal-wrapper><h3>Abstract</h3><p class=pub-abstract><p>abstract</p><p>AbstractIn this paper, we present EnvyDepth, an interface for recovering local illumination from a single HDR environment map. In EnvyDepth, the user quickly indicates strokes to mark regions of the environment map that should be grouped together in a single geometric primitive. From these annotated strokes, EnvyDepth uses edit propagation to create a detailed collection of virtual point lights that reproduce both the local and the distant lighting effects in the original scene. When compared to the sole use of the distant illumination, the added spatial information better reproduces a variety of local effects such as shadows, highlights and caustics. Without the effort needed to create precise scene reconstructions, EnvyDepth annotations take only tens of seconds to produce a plausible lighting without visible artifacts. This is easy to obtain even in the case of complex scenes, both indoors and outdoors. The generated lighting environments work well in a production pipeline since they are efficient to use and able to produce accurate renderings.</p><p>Errata: the Amsterdam Road example is not in Amsterdam but in Hague.</p><p>SoftwareA first version of EnvyDepth can be now dowloaded here; spiced by Piccante. Tutorial Video</p></p><div class=article-style><p><a href=https://vcgdata.isti.cnr.it/Publicstions/2013/BCDCPS13/envy_depth.zip target=_blank rel=noopener>here</a></p><p><a href=http://piccantelib.net target=_blank rel=noopener>Piccante</a></p><iframe width=580 height=435 src=https://www.youtube.com/embed/UtOsYqlvLfE frameborder=0 frameborder=0 allowfullscreen></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2013%2FBCDCPS13%2F&amp;text=EnvyDepth%3A+An+Interface+for+Recovering+Local+Natural+Illumination+from+Environment+Maps" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2013%2FBCDCPS13%2F&amp;t=EnvyDepth%3A+An+Interface+for+Recovering+Local+Natural+Illumination+from+Environment+Maps" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=EnvyDepth%3A%20An%20Interface%20for%20Recovering%20Local%20Natural%20Illumination%20from%20Environment%20Maps&amp;body=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2013%2FBCDCPS13%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2013%2FBCDCPS13%2F&amp;title=EnvyDepth%3A+An+Interface+for+Recovering+Local+Natural+Illumination+from+Environment+Maps" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=EnvyDepth%3A+An+Interface+for+Recovering+Local+Natural+Illumination+from+Environment+Maps%20http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2013%2FBCDCPS13%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=http%3A%2F%2Fvcg.isti.cnr.it%2Fpublication%2F2013%2FBCDCPS13%2F&amp;title=EnvyDepth%3A+An+Interface+for+Recovering+Local+Natural+Illumination+from+Environment+Maps" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=/author/Francesco-Banterle/><img class="avatar mr-3 avatar-circle" src=/author/Francesco-Banterle/avatar_hudde941c59209505f0908e56563720662_57012_270x270_fill_q75_lanczos_center.jpg alt="Francesco Banterle"></a><div class=media-body><h5 class=card-title><a href=/author/Francesco-Banterle/>Francesco Banterle</a></h5><h6 class=card-subtitle>Researcher</h6><p class=card-text>Researcher at the Visual Computing Lab</p><ul class=network-icon aria-hidden=true><li><a href=mailto:francesco.banterle@isti.cnr.it><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.it/citations?user=lP2Utx8AAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://orcid.org/0000-0002-6374-6657 target=_blank rel=noopener><i class="fab fa-orcid"></i></a></li><li><a href=https://github.com/banterle target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://twitter.com/frabante target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/author/Marco-Callieri/><img class="avatar mr-3 avatar-circle" src=/author/Marco-Callieri/avatar_hu27f7dc34c9db8fd2b063f3fba6be9864_618512_270x270_fill_q75_lanczos_center.jpg alt="Marco Callieri"></a><div class=media-body><h5 class=card-title><a href=/author/Marco-Callieri/>Marco Callieri</a></h5><h6 class=card-subtitle>Senior Researcher</h6><p class=card-text>Digital Technologies for Cultural Heritage</p><ul class=network-icon aria-hidden=true><li><a href=mailto:callieri@isti.cnr.it><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=Vshulj0AAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://github.com/mcallieri target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div><div class="media author-card content-widget-hr"><a href=/author/Massimiliano-Corsini/><img class="avatar mr-3 avatar-circle" src=/author/Massimiliano-Corsini/avatar_hu37b7c957d32056484806515ec5c1c696_38296_270x270_fill_q75_lanczos_center.jpg alt="Massimiliano Corsini"></a><div class=media-body><h5 class=card-title><a href=/author/Massimiliano-Corsini/>Massimiliano Corsini</a></h5><h6 class=card-subtitle>Senior Researcher</h6><p class=card-text>Imaging, 3D, and AI</p><ul class=network-icon aria-hidden=true><li><a href=mailto:massimiliano.corsini@isti.cnr.it><i class="fas fa-envelope"></i></a></li><li><a href="https://scholar.google.com/citations?user=jU8HCCkAAAAJ&amp;hl=it" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://orcid.org/0000-0003-0543-1638 target=_blank rel=noopener><i class="fab fa-orcid"></i></a></li><li><a href=https://github.com/maxcorsini target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><div class="powered-by social"><div class=d-lg-inline-flex><a class=navbar-brand href="https://twitter.com/visualcnr?lang=en"><img src=/media/X-c_hue8fe063a1fcec03db656afc3cc1bf40d_4700_0x140_resize_lanczos_3.png alt=X class=logo_light>
<img src=/media/X_hu910497ff4d276c94260d7322781984c6_4293_0x140_resize_lanczos_3.png alt=X class=logo_dark>
</a><a class=navbar-brand href=https://www.youtube.com/@VisualComputingLab><img src=/media/youtube-c_huedb2ca5c3d726980f90576391adac131_7778_0x140_resize_lanczos_3.png alt=Youtube class=logo_light>
<img src=/media/youtube_hu346e00c25b9c4e4a11c9cf2ace0c5f8a_7418_0x140_resize_lanczos_3.png alt=Youtube class=logo_dark></a></div></div><div class="powered-by logos"><div class=d-lg-inline-flex><a class=navbar-brand href=https:\\www.cnr.it><img src=/media/cnr_large_hu154e7a767a31e0854ddc521bcb58b068_47394_0x140_resize_lanczos_3.png alt=CNR class=logo_light>
<img src=/media/cnr_large_white_hu96c8e951d9795328236a14dba01a5353_34600_0x140_resize_lanczos_3.png alt=CNR class=logo_dark>
</a><a class=navbar-brand href=https:\\www.isti.cnr.it><img src=/media/isti_large_hue3ef55169739ec78d195cc0ccbe3fc8b_95363_0x140_resize_lanczos_3.png alt=ISTI class=logo_light>
<img src=/media/isti_large_white_hu72f866e760b3503504a1ced7937ab9a7_49065_0x140_resize_lanczos_3.png alt=ISTI class=logo_dark>
</a><a class=navbar-brand href=/><img src=/media/logo_hu99235f83657eda8c6e6761af9b1430df_128410_0x140_resize_lanczos_3.png alt="Visual Computing Lab"></a></div></div><p class=powered-by>Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> — the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.391d344a129df56f7ad674c2c2ed04e8.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.7f5ebaff62ae468cff8bb3dd1337bb9b.js></script><script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js type=module></script><html><head><script>function toggleFunction(e){e.classList.contains("toggle")?e.classList.remove("toggle"):e.classList.add("toggle")}window.onload=function(){var e=document.querySelectorAll("#section-collection.activities .article-style");for(i=0;i<e.length;i++)e[i].onclick=function(){toggleFunction(this)};e=document.querySelectorAll("#section-collection.activities .summary-link");for(i=0;i<e.length;i++)e[i].removeAttribute("href")}</script></head><body></html></body></html>