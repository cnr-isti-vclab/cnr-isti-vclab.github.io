<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.7"><link rel=stylesheet href=/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.8ae4440109d7bd8c3cc2e20e4692bb95.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=description content="At the Visual Computing Lab we study new methods in Visual AI, the discipline that teaches machines to make sense of and act on visual data. Our research in Visual AI encompasses different formats – from images and videos to RTI and 3D surfaces – and applications – from AI-assisted 3D object design and architectural geometry to environmental monitoring, from 3D acquisition and reconstruction to Virtual and Augmented Reality."><link rel=alternate hreflang=en-us href=http://vcg.isti.cnr.it/research/visual-ai/><link rel=canonical href=http://vcg.isti.cnr.it/research/visual-ai/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu99235f83657eda8c6e6761af9b1430df_128410_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu99235f83657eda8c6e6761af9b1430df_128410_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@GetResearchDev"><meta property="twitter:creator" content="@GetResearchDev"><meta property="twitter:image" content="http://vcg.isti.cnr.it/research/visual-ai/featured.jpg"><meta property="og:type" content="website"><meta property="og:site_name" content="Visual Computing Lab"><meta property="og:url" content="http://vcg.isti.cnr.it/research/visual-ai/"><meta property="og:title" content="Visual AI | Visual Computing Lab"><meta property="og:description" content="At the Visual Computing Lab we study new methods in Visual AI, the discipline that teaches machines to make sense of and act on visual data. Our research in Visual AI encompasses different formats – from images and videos to RTI and 3D surfaces – and applications – from AI-assisted 3D object design and architectural geometry to environmental monitoring, from 3D acquisition and reconstruction to Virtual and Augmented Reality."><meta property="og:image" content="http://vcg.isti.cnr.it/research/visual-ai/featured.jpg"><meta property="og:locale" content="en-us"><title>Visual AI | Visual Computing Lab</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=0c85d155d021c2cec9d4e1d89239fa35><script src=/js/wowchemy-init.min.af58bb76e2f77811e22a6e43ed4f8bfa.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Visual Computing Lab</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Visual Computing Lab</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/research data-target=[]><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/results><span>Activities</span></a></li><li class=nav-item><a class=nav-link href=/software><span>Software</span></a></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><span class="js-widget-page d-none"></span><section id=desc class="home-section wg-markdown"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0>Visual AI</h1></div><div class=col-12><p>Research on the foundational themes of Computer graphis like quad meshing, texture parametrization, Hexahedral Meshing, etc. has been always one of the basic line of our lab.</p><p>Our activity on Geometry Processing includes methodologies for shape analysis and characterization, mesh parametrization and its applications. First, we aim to apply such techniques for re-meshing, compression and visualization.</p><p>This research activity has been the driving force for many contributions in other research lines like <a href=/research/digital-fabrication>digital fabrication</a>, <a href=/research/digitization>digital heritage</a>, providing tools for efficient geometric modeling, physical simulation, numerical optimization and shape analysis. The results of this research have been published in several papers in top-tier conferences and journals in the field of Computer Graphics and Computer-Aided Design (ACM Transactions on Graphics, SIGGRAPH, SIGGRAPH Asia, Eurographics, etc.).</p><p>Relevant expertise in digital fabrication has been exploited in the context of several research projects, including Italian Government PRIN <a href=https://www.isti.cnr.it/en/research/project-detail/7800/DSurf_DSurf:_Scalable_Computational_Methods_for_3D_Printing_Surfaces target=_blank rel=noopener>DSurf</a>, EU Horizon 2020 ITN <a href=https://evocation.eu target=_blank rel=noopener>Evocation</a>, and EU Horizon 2020 <a href=https://emotiveproject.eu target=_blank rel=noopener>EMOTIVE</a>.</p><p>Below some of the latest papers on this subject are listed.</p></div></div></div></section><section id=papers class="home-section wg-collection"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class=col-12><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2024/FLCMG24-GeometricLearningxShells/>Geometric deep learning for statics-aware grid shells</a></div><a href=/publication/2024/FLCMG24-GeometricLearningxShells/ class=summary-link><div class=article-style>This paper introduces a novel method for shape optimization and form-finding of free-form, triangular grid shells, based on geometric …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/Andrea-Favilli/>Andrea Favilli</a></span>, <span><a href=/author/Francesco-Laccone/>Francesco Laccone</a></span>, <span><a href=/author/Paolo-Cignoni/>Paolo Cignoni</a></span>, <span><a href=/author/Luigi-Malomo/>Luigi Malomo</a></span>, <span><a href=/author/Daniela-Giorgi/>Daniela Giorgi</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://vcgdata.isti.cnr.it/Publications/2024/FLCMG24-GeometricLearningxShells/FLCMG24-GeometricLearningxShells.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2024/FLCMG24-GeometricLearningxShells/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/cnr-isti-vclab/GeomDL4GridShell#geometric-deep-learning-for-statics-aware-grid-shells target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1016/j.compstruc.2023.107238 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/2024/FLCMG24-GeometricLearningxShells/><img src=/publication/2024/FLCMG24-GeometricLearningxShells/featured_hu216b13a12504e1da77c0b9a171b36535_1619772_12a092ca45e5eaf72bc559c947f2eb62.webp height=127 width=150 alt="Geometric deep learning for statics-aware grid shells" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2023/VCC23-SunItalIA/>Social and hUman ceNtered XR</a></div><a href=/publication/2023/VCC23-SunItalIA/ class=summary-link><div class=article-style>The Social and hUman ceNtered XR (SUN) project is focused on developing eXtended Reality (XR) solutions that integrate the physical and …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/Claudio-Vairo/>Claudio Vairo</a></span>, <span><a href=/author/Marco-Callieri/>Marco Callieri</a></span>, <span><a href=/author/Fabio-Carrara/>Fabio Carrara</a></span>, <span><a href=/author/Paolo-Cignoni/>Paolo Cignoni</a></span>, <span><a href=/author/Marco-Di-Benedetto/>Marco Di Benedetto</a></span>, <span><a href=/author/Claudio-Gennaro/>Claudio Gennaro</a></span>, <span><a href=/author/Daniela-Giorgi/>Daniela Giorgi</a></span>, <span><a href=/author/Gianpaolo-Palma/>Gianpaolo Palma</a></span>, <span><a href=/author/Lucia-Vadicamo/>Lucia Vadicamo</a></span>, <span><a href=/author/Giuseppe-Amato/>Giuseppe Amato</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ceur-ws.org/Vol-3486/46.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2023/VCC23-SunItalIA/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2023/VCC23-SunItalIA/><img src=/publication/2023/VCC23-SunItalIA/featured_hu8acf9ad4591b3d317659ac04f375c6fa_18337_ad01d2e2fe90431b991e38929ccf11af.webp height=81 width=150 alt="Social and hUman ceNtered XR" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2023/MCT23-TextureInpainting/>Texture Inpainting for Photogrammetric Models</a></div><a href=/publication/2023/MCT23-TextureInpainting/ class=summary-link><div class=article-style>We devise a technique designed to remove the texturing artefacts that are typical of 3D models representing real-world objects, …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/Andrea-Maggiordomo/>Andrea Maggiordomo</a></span>, <span><a href=/author/Paolo-Cignoni/>Paolo Cignoni</a></span>, <span><a href=/author/Marco-Tarini/>Marco Tarini</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://vcgdata.isti.cnr.it/Publications/2023/MCT23-TextureInpainting/2023TextureInpainting.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2023/MCT23-TextureInpainting/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/%20https://doi.org/10.1111/cgf.14735 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/2023/MCT23-TextureInpainting/><img src=/publication/2023/MCT23-TextureInpainting/featured_hu8e229689b2011811afb8c127c5becfbb_160412_6ae16357d69abdd724cd8bdd45d64f14.webp height=58 width=150 alt="Texture Inpainting for Photogrammetric Models" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022/PGDCPCC22/>On assisting and automatizing the semantic segmentation of masonry walls</a></div><a href=/publication/2022/PGDCPCC22/ class=summary-link><div class=article-style></div></a><div class="stream-meta article-metadata"><div><span><a href=/author/Gaia-Pavoni/>Gaia Pavoni</a></span>, <span><a href=/author/Francesca-Giuliani/>Francesca Giuliani</a></span>, <span><a href=/author/Anna-De-Falco/>Anna De Falco</a></span>, <span><a href=/author/Massimiliano-Corsini/>Massimiliano Corsini</a></span>, <span><a href=/author/Federico-Ponchio/>Federico Ponchio</a></span>, <span><a href=/author/Marco-Callieri/>Marco Callieri</a></span>, <span><a href=/author/Paolo-Cignoni/>Paolo Cignoni</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://vcgdata.isti.cnr.it/Publications/2022/PGDCPCC22/TAGLAB_WALLS_EXTENDED.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022/PGDCPCC22/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2022/PGDCPCC22/><img src=/publication/2022/PGDCPCC22/featured_hub012649aadeab6b7cd4c701050b09c00_92012_0538a242a514dbe5b5031eb7ac164beb.webp height=39 width=150 alt="On assisting and automatizing the semantic segmentation of masonry walls" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2021/PCPEPSC21/>TagLab: AI-assisted annotation for the fast and accurate semantic segmentation of coral reef orthoimages</a></div><div class="stream-meta article-metadata"><div><span><a href=/author/Gaia-Pavoni/>Gaia Pavoni</a></span>, <span><a href=/author/Massimiliano-Corsini/>Massimiliano Corsini</a></span>, <span><a href=/author/Federico-Ponchio/>Federico Ponchio</a></span>, <span><a href=/author/Clinton-Edwards/>Clinton Edwards</a></span>, <span><a href=/author/Nicole-Pedersen/>Nicole Pedersen</a></span>, <span><a href=/author/Stuart-Sandin/>Stuart Sandin</a></span>, <span><a href=/author/Paolo-Cignoni/>Paolo Cignoni</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://vcgdata.isti.cnr.it/Publications/2021/PCPEPSC21/rob.22049.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2021/PCPEPSC21/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/2021/PCPEPSC21/><img src=/publication/2021/PCPEPSC21/featured_hued8d7de5ccc7c440d0e8e03dffc18262_364538_b94f99d343cf8aac073bcd1c5e22c331.webp height=81 width=150 alt="TagLab: AI-assisted annotation for the fast and accurate semantic segmentation of coral reef orthoimages" loading=lazy></a></div></div></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> — the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.ff7771056d34ad9f2de2d8f6a466e748.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.7f5ebaff62ae468cff8bb3dd1337bb9b.js></script><script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js type=module></script></body></html>